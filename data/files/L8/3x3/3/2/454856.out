Job running on nodes: jean-zay-iam11
recursion 1 started at Tue Nov  5 01:17:26 PM CET 2024
WARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.
python -u -O /lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro_nocallback/deepnets/optimization/run.py --L=8 --J 0.8 1.0 --n_blocks 12 --features 72 --expansion_factor=2 --downsample_factor=2 --kernel_width=3 --output_head=Vanilla --samples_per_rank=512 --chains_per_rank=512 --discard_fraction=0.0 --iters 2500 2500 2500 2500 --lr 0.01 0.01 0.01 0.01 --alpha 0.5 0.5 0.5 0.5 --diag_shift 0.01 0.01 0.01 0.01 --diag_shift_end 0.0001 0.0001 0.0001 0.0001 --r=1e-06 --chunk_size=512 --save_every=100 --symmetries=0 --symmetry_ramping=1 --momentum=0.9 --post_iters=50 --double_precision=1 --time_it=0 --show_progress=0 --checkpoint=1 --seed=293  --save_base /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/ >> /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/${SLURM_JOB_ID}.out &
Configuring sharding...
Number of distributed processes = 1
Number of total devices: 8
0/1 : global [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : local [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : hostname:  jean-zay-iam11
Double precision enabled =  True
chunk_size = 512
Running optimization...
Symmetry stage 0 on process 0:
Total number of model parameters = 276552
Using minSR
restoring checkpoint #2500
restoring checkpoint #2500
Symmetry stage 1 on process 0:
Total number of model parameters = 276552
Using minSR
restoring checkpoint #2500
2024-11-05 13:22:33.645487: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[16384,72,6,6]{3,2,1,0}, f64[16384,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 13:22:38.831077: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 6.185671113s
Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[16384,72,6,6]{3,2,1,0}, f64[16384,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
Symmetry stage 2 on process 0:
Total number of model parameters = 276552
Using minSR
restoring checkpoint #2500
2024-11-05 13:23:37.656833: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[32768,72,6,6]{3,2,1,0}, f64[32768,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-11-05 13:23:49.318770: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 12.662006985s
Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[32768,72,6,6]{3,2,1,0}, f64[32768,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
Symmetry stage 3 on process 0:
Total number of model parameters = 276552
Using minSR
restoring checkpoint #300
2024-11-05 13:25:26.222009: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3020] Can't reduce memory use below 56.38GiB (60537601275 bytes) by rematerialization; only reduced to 61.61GiB (66153072404 bytes), down from 107.84GiB (115789703628 bytes) originally
2024-11-05 13:25:48.706464: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_1_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.706997: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.707113 1197973 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.707936: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_2_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.708427: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.708492 1197976 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.709616: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_6_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.710189: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.710302 1197988 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.710965: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_3_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.711438: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.711501 1197979 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.712389: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_7_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.712893: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.712981 1197991 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.713773: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.714270: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.714359 1197970 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.715649: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_5_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.716179: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.716284 1197985 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
2024-11-05 13:25:48.717325: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_4_bfc) ran out of memory trying to allocate 78.16GiB (rounded to 83922313472)requested by op 
2024-11-05 13:25:48.717873: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1105 13:25:48.717975 1197982 pjrt_stream_executor_client.cc:3085] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83922313368 bytes.
Out of memory, reducing chunk_size to 256 and retrying
restoring checkpoint #300
WARNING:absl:[process=0][thread=async_save_6] Skipping merge of OCDBT checkpoints: No per-process OCDBT checkpoint subdirs found in /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers.orbax-checkpoint-tmp-4, 
ERROR:absl:[process=0] Failed to run 3 Handler Commit operations or the Commit callback in background save thread, directory: /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400
Traceback (most recent call last):
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 153, in _thread_func
    on_commit_callback()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 368, in _callback
    self._handler.finalize(tmpdir.get())
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/composite_checkpoint_handler.py", line 867, in finalize
    tmp_dir.finalize()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/path/atomicity.py", line 325, in finalize
    self._tmp_path.rename(self._final_path)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/etils/epath/gpath.py", line 266, in rename
    backend.rename(self._path_str, os.fspath(target))
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/etils/epath/backend.py", line 214, in rename
    os.rename(path, dst)
FileNotFoundError: [Errno 2] No such file or directory: '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers.orbax-checkpoint-tmp-4' -> '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers'
ERROR:absl:[process=0][thread=MainThread][step=400][wait_until_finished] Save Finalize thread (save_finalize) failed.
Traceback (most recent call last):
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1703, in wait_until_finished
    self._finalize_thread.join()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 153, in join
    raise self.exception
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 146, in run
    super().run()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1800, in _finalize
    self._wait_for_checkpointers()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1672, in _wait_for_checkpointers
    self._checkpointer.wait_until_finished()  # pytype: disable=attribute-error
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 437, in wait_until_finished
    self._async_manager.wait_until_finished()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 234, in wait_until_finished
    self.check_for_errors()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 209, in check_for_errors
    raise exception  # pylint: disable=raising-bad-type
    ^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 153, in _thread_func
    on_commit_callback()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 368, in _callback
    self._handler.finalize(tmpdir.get())
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/composite_checkpoint_handler.py", line 867, in finalize
    tmp_dir.finalize()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/path/atomicity.py", line 325, in finalize
    self._tmp_path.rename(self._final_path)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/etils/epath/gpath.py", line 266, in rename
    backend.rename(self._path_str, os.fspath(target))
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/etils/epath/backend.py", line 214, in rename
    os.rename(path, dst)
FileNotFoundError: [Errno 2] No such file or directory: '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers.orbax-checkpoint-tmp-4' -> '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers'
Traceback (most recent call last):
  File "//lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro_nocallback/deepnets/optimization/run.py", line 158, in <module>
    sim_time, n_parameters = optimization(
                             ^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro_nocallback/deepnets/optimization/protocols.py", line 679, in symmetry_ramp_checkpoint
    gs.run_checkpointed(
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro_nocallback/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 216, in run_checkpointed
    self._save_checkpoint(chkptr, loggers, callbacks)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/netket/utils/timing.py", line 230, in timed_function
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro_nocallback/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 493, in _save_checkpoint
    chkptr.save(
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1140, in save
    self.wait_until_finished()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1703, in wait_until_finished
    self._finalize_thread.join()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 153, in join
    raise self.exception
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 146, in run
    super().run()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1800, in _finalize
    self._wait_for_checkpointers()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1672, in _wait_for_checkpointers
    self._checkpointer.wait_until_finished()  # pytype: disable=attribute-error
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 437, in wait_until_finished
    self._async_manager.wait_until_finished()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 234, in wait_until_finished
    self.check_for_errors()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 209, in check_for_errors
    raise exception  # pylint: disable=raising-bad-type
    ^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 153, in _thread_func
    on_commit_callback()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 368, in _callback
    self._handler.finalize(tmpdir.get())
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/_src/handlers/composite_checkpoint_handler.py", line 867, in finalize
    tmp_dir.finalize()
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/orbax/checkpoint/path/atomicity.py", line 325, in finalize
    self._tmp_path.rename(self._final_path)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/etils/epath/gpath.py", line 266, in rename
    backend.rename(self._path_str, os.fspath(target))
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu_nocallback/lib/python3.11/site-packages/etils/epath/backend.py", line 214, in rename
    os.rename(path, dst)
FileNotFoundError: [Errno 2] No such file or directory: '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers.orbax-checkpoint-tmp-4' -> '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_3x3/2/checkpoint3/400.orbax-checkpoint-tmp-0/loggers'
Time limit reached, resubmitting 1th sbatch...
Submitted batch job 555975
