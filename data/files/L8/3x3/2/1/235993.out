Job running on nodes: jean-zay-iam52
Loading cpuarch/amd
  WARNING: Using "module load cpuarch/amd" is deprecated,
    use "module load arch/a100" instead.
recursion 1 started at Sat Oct 19 09:15:11 PM CEST 2024
python -u -O /lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py --L=10 --J 0.8 1.0 --n_blocks 4 --features 72 --expansion_factor=2 --downsample_factor=2 --kernel_width=3 --output_head=Vanilla --samples_per_rank=512 --chains_per_rank=512 --discard_fraction=0.0 --iters 2500 2500 2500 2500 --lr 0.01 0.01 0.01 0.01 --alpha 0.5 0.5 0.5 0.5 --diag_shift 0.01 0.01 0.01 0.01 --diag_shift_end 0.0001 0.0001 0.0001 0.0001 --r=1e-06 --chunk_size=256 --save_every=100 --symmetries=0 --symmetry_ramping=1 --momentum=0.9 --post_iters=50 --double_precision=1 --time_it=0 --show_progress=1 --checkpoint=1 --seed=416  --save_base /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/02_10_24/L=8/symm_ramp/1/ >> /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/02_10_24/L=8/symm_ramp/1/${SLURM_JOB_ID}.out &
Configuring sharding...
Number of distributed processes = 1
Number of total devices: 8
0/1 : global [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : local [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : hostname:  jean-zay-iam52
2024-10-19 21:18:00.880828: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.68. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
Double precision enabled =  True
chunk_size = 256
Running optimization...
Symmetry stage 0 on process 0:
Total number of model parameters = 99720
Using minSR
restoring checkpoint #2500
Error while restoring checkpoint:  'NoneType' object is not iterable
============================================
raising Error on 0


============================================
The error above is printed only from rank 0 and is umangled.
Below there is mangled output from non rank 0s
============================================


  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:59<?, ?it/s]
Traceback (most recent call last):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/utils/iter_utils.py", line 20, in cleanup_checkpointer
    yield checkpointer
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 425, in _restore_checkpoint
    for _cb, _restored_cb in zip(
                             ^^^^
TypeError: 'NoneType' object is not iterable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py", line 158, in <module>
    sim_time, n_parameters = optimization(
                             ^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/protocols.py", line 669, in symmetry_ramp_checkpoint
    gs.run_checkpointed(
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 200, in run_checkpointed
    loggers, callbacks, starting_iter = self._restore_checkpoint(
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/netket/utils/timing.py", line 230, in timed_function
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 368, in _restore_checkpoint
    with cleanup_checkpointer(chkptr, close_checkpointer=created_manager):
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/utils/iter_utils.py", line 34, in cleanup_checkpointer
    raise Exception(
Exception: Error while restoring checkpoint. There might be a mismatch between run files, system sizes or other things.

The original exception error is reported above.
srun: error: jean-zay-iam52: task 0: Exited with exit code 1
srun: Terminating StepId=235993.0
