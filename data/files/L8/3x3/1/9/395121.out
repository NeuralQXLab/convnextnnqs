Job running on nodes: jean-zay-iam08
recursion  started at Mon Oct 28 08:00:00 PM CET 2024
python -u -O /lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py --L=8 --J 0.8 1.0 --n_blocks 4 --features 72 --expansion_factor=2 --downsample_factor=2 --kernel_width=3 --output_head=Vanilla --samples_per_rank=512 --chains_per_rank=512 --discard_fraction=0.0 --iters 2500 2500 2500 2500 --lr 0.01 0.01 0.01 0.01 --alpha 0.5 0.5 0.5 0.5 --diag_shift 0.01 0.01 0.01 0.01 --diag_shift_end 0.0001 0.0001 0.0001 0.0001 --r=1e-06 --chunk_size=512 --save_every=100 --symmetries=0 --symmetry_ramping=1 --momentum=0.9 --post_iters=50 --double_precision=1 --time_it=0 --show_progress=0 --checkpoint=1 --seed=339  --save_base /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_2x2/9/ >> /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_2x2/9/${SLURM_JOB_ID}.out &
Configuring sharding...
Number of distributed processes = 1
Number of total devices: 8
0/1 : global [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : local [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : hostname:  jean-zay-iam08
Double precision enabled =  True
chunk_size = 512
Running optimization...
Symmetry stage 0 on process 0:
Total number of model parameters = 99720
Using minSR
restoring checkpoint #0
Symmetry stage 1 on process 0:
Total number of model parameters = 99720
Using minSR
2024-10-28 20:59:29.162096: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[16384,72,6,6]{3,2,1,0}, f64[16384,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-10-28 20:59:34.247799: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 6.08579257s
Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[16384,72,6,6]{3,2,1,0}, f64[16384,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
Symmetry stage 2 on process 0:
Total number of model parameters = 99720
Using minSR
2024-10-28 23:06:00.432933: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[32768,72,6,6]{3,2,1,0}, f64[32768,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-10-28 23:06:10.903122: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 11.47028667s
Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[32768,72,6,6]{3,2,1,0}, f64[32768,72,4,4]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
Traceback (most recent call last):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py", line 158, in <module>
    sim_time, n_parameters = optimization(
                             ^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/protocols.py", line 688, in symmetry_ramp_checkpoint
    gs.run_checkpointed(
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 216, in run_checkpointed
    self._save_checkpoint(chkptr, loggers, callbacks)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/netket/utils/timing.py", line 230, in timed_function
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 493, in _save_checkpoint
    chkptr.save(
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/checkpoint_manager.py", line 1236, in save
    self._checkpointer.save(save_directory, args=args)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 423, in save
    asyncio_utils.run_sync(self._save(directory, *args, force=force, **kwargs))
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/_src/asyncio_utils.py", line 50, in run_sync
    return asyncio.run(coro)
           ^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/asyncio/runners.py", line 190, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/async_checkpointer.py", line 348, in _save
    tmpdir = await self.create_temporary_path(directory)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/checkpointer.py", line 158, in create_temporary_path
    await atomicity.create_all(
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/path/atomicity.py", line 479, in create_all
    await asyncio.gather(*[path.create() for path in paths])
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/path/atomicity.py", line 305, in create
    return await _create_tmp_directory(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/path/atomicity.py", line 177, in _create_tmp_directory
    await async_utils.async_makedirs(
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/orbax/checkpoint/_src/asyncio_utils.py", line 34, in run
    return await loop.run_in_executor(executor, partial_func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/etils/epath/gpath.py", line 205, in mkdir
    self._backend.makedirs(self._path_str, exist_ok=exist_ok, mode=mode)
  File "/linkhome/rech/gencpt01/uvm91ap/.conda/envs/amd_gpu/lib/python3.11/site-packages/etils/epath/backend.py", line 170, in makedirs
    os.makedirs(path, exist_ok=exist_ok, mode=mode)
  File "<frozen os>", line 225, in makedirs
OSError: [Errno 122] Disk quota exceeded: '/gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/17_10_24/L=8/symm_ramp_2x2/9/checkpoint2/1300.orbax-checkpoint-tmp-594'
/var/spool/slurmd/job395121/slurm_script: line 26: [: : integer expression expected
Time limit reached, resubmitting th sbatch...
Submitted batch job 453560
