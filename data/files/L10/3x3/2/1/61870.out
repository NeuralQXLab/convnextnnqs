Job running on nodes: jean-zay-iam34
Loading cpuarch/amd
  WARNING: Using "module load cpuarch/amd" is deprecated,
    use "module load arch/a100" instead.
recursion 1 started at Mon Oct  7 04:27:48 AM CEST 2024
python -u -O /lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py --L=10 --J 0.8 1.0 --n_blocks 4 --features 72 --expansion_factor=2 --downsample_factor=2 --kernel_width=3 --output_head=Vanilla --samples_per_rank=512 --chains_per_rank=512 --discard_fraction=0.0 --iters 2500 2500 2500 2500 --lr 0.01 0.01 0.01 0.01 --alpha 0.5 0.5 0.5 0.5 --diag_shift 0.01 0.01 0.01 0.01 --diag_shift_end 0.0001 0.0001 0.0001 0.0001 --r=1e-06 --chunk_size=512 --save_every=100 --symmetries=0 --symmetry_ramping=1 --momentum=0.9 --post_iters=50 --double_precision=1 --time_it=0 --show_progress=1 --checkpoint=1 --seed=416  --save_base /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/02_10_24/L=8/symm_ramp/1/ >> /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/02_10_24/L=8/symm_ramp/1/${SLURM_JOB_ID}.out &
Configuring sharding...
Number of distributed processes = 1
Number of total devices: 8
0/1 : global [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : local [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : hostname:  jean-zay-iam34
Double precision enabled =  True
2024-10-07 04:28:12.036126: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.68. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
Running optimization...
Symmetry stage 0 on process 0:
Total number of model parameters = 99720
Using minSR
restoring checkpoint #2500
  0%|          | 0/1 [00:00<?, ?it/s]  0%|          | 0/1 [00:26<?, ?it/s, Energy=-179.404-0.003j ± 0.029 [σ²=3.458]]2500it [00:26, 95.42it/s, Energy=-179.404-0.003j ± 0.029 [σ²=3.458]]            2500it [00:26, 95.13it/s, Energy=-179.404-0.003j ± 0.029 [σ²=3.458]]
restoring checkpoint #2500
  0%|          | 0/2500 [00:00<?, ?it/s]  0%|          | 0/2500 [00:01<?, ?it/s, Energy=-179.404-0.003j ± 0.029 [σ²=3.458]]100%|██████████| 2500/2500 [00:01<00:00, 1355.08it/s, Energy=-179.404-0.003j ± 0.029 [σ²=3.458]]100%|██████████| 2500/2500 [00:01<00:00, 1312.57it/s, Energy=-179.404-0.003j ± 0.029 [σ²=3.458]]
Symmetry stage 1 on process 0:
Total number of model parameters = 99720
Using minSR
restoring checkpoint #2500
  0%|          | 0/2500 [00:00<?, ?it/s]2024-10-07 04:29:06.984218: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[16384,72,7,7]{3,2,1,0}, f64[16384,72,5,5]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-10-07 04:29:12.458038: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 6.47388292s
Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[16384,72,7,7]{3,2,1,0}, f64[16384,72,5,5]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
  0%|          | 0/2500 [00:26<?, ?it/s, Energy=-179.656+0.001j ± 0.021 [σ²=1.801]]100%|██████████| 2500/2500 [00:26<00:00, 95.07it/s, Energy=-179.656+0.001j ± 0.021 [σ²=1.801]]100%|██████████| 2500/2500 [00:26<00:00, 95.02it/s, Energy=-179.656+0.001j ± 0.021 [σ²=1.801]]
Symmetry stage 2 on process 0:
Total number of model parameters = 99720
Using minSR
restoring checkpoint #2500
  0%|          | 0/2500 [00:00<?, ?it/s]2024-10-07 04:29:42.088723: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[32768,72,7,7]{3,2,1,0}, f64[32768,72,5,5]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
2024-10-07 04:29:52.052799: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 10.964123401s
Trying algorithm eng20{k2=6,k3=0} for conv (f64[72,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f64[32768,72,7,7]{3,2,1,0}, f64[32768,72,5,5]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, feature_group_count=72, custom_call_target="__cudnn$convBackwardFilter", backend_config={"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"leakyrelu_alpha":0,"side_input_scale":0},"force_earliest_schedule":false,"operation_queue_id":"0","wait_on_operation_queues":[]} is taking a while...
  0%|          | 0/2500 [00:34<?, ?it/s, Energy=-179.658+0.000j ± 0.021 [σ²=1.749]]100%|██████████| 2500/2500 [00:34<00:00, 72.79it/s, Energy=-179.658+0.000j ± 0.021 [σ²=1.749]]100%|██████████| 2500/2500 [00:34<00:00, 72.77it/s, Energy=-179.658+0.000j ± 0.021 [σ²=1.749]]
Symmetry stage 3 on process 0:
Total number of model parameters = 99720
Using minSR
restoring checkpoint #0
  0%|          | 0/2500 [00:00<?, ?it/s]  0%|          | 0/2500 [00:40<?, ?it/s, Energy=-179.630+0.043j ± 0.081 [σ²=27.033]]  0%|          | 0/2500 [00:40<?, ?it/s, Energy=-179.630+0.043j ± 0.081 [σ²=27.033]]2024-10-07 04:31:30.336682: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_2_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.337115: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.337200  663899 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.337471: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.337898: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.337971  663895 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.338353: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_5_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.338636: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.338697  663905 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.339616: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_1_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.339983: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.340043  663897 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.340761: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_4_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.341219: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.341294  663903 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.341742: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_6_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.341996: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.342053  663907 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.342647: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_3_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.343095: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.343172  663901 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
2024-10-07 04:31:30.343720: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_7_bfc) ran out of memory trying to allocate 82.99GiB (rounded to 89112523264)requested by op 
2024-10-07 04:31:30.344191: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1007 04:31:30.344262  663909 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.
  0%|          | 0/2500 [01:24<?, ?it/s, Energy=-179.630+0.043j ± 0.081 [σ²=27.033]]
Traceback (most recent call last):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py", line 157, in <module>
    sim_time, n_parameters = optimization(
                             ^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/protocols.py", line 674, in symmetry_ramp_checkpoint
    gs.run_checkpointed(
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 214, in run_checkpointed
    for step in self.iter(n_iter, step_size, start=starting_iter):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 69, in iter
    dp = self._forward_and_backward()
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_pro/_src/driver/vmc_srt_ntk.py", line 371, in _forward_and_backward
    updates, self._cplx_split_updates, _ = SRt_ntk(
                                           ^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 89112523152 bytes.: while running replica 0 and partition 0 of a replicated computation (other replicas may have failed as well).
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
srun: error: jean-zay-iam34: task 0: Exited with exit code 1
srun: Terminating StepId=61870.0
