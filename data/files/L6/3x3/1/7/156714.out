Job running on nodes: jean-zay-iam28
recursion 0 started at Thu Oct 17 08:00:49 AM CEST 2024
python -u -O /lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py --L=6 --J 0.8 1.0 --n_blocks 8 --features 72 --expansion_factor=2 --downsample_factor=2 --kernel_width=3 --output_head=Vanilla --samples_per_rank=512 --chains_per_rank=512 --discard_fraction=0.0 --iters 2500 2500 2500 2500 --lr 0.01 0.01 0.01 0.01 --alpha 0.5 0.5 0.5 0.5 --diag_shift 0.01 0.01 0.01 0.01 --diag_shift_end 0.0001 0.0001 0.0001 0.0001 --r=1e-06 --chunk_size=512 --save_every=100 --symmetries=0 --symmetry_ramping=1 --momentum=0.9 --post_iters=50 --double_precision=1 --time_it=0 --show_progress=0 --checkpoint=1 --seed=78  --save_base /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/14_10_24/L=6/symm_ramp_3x3/7/ >> /gpfswork/rech/iqu/uvm91ap/projects/deepNQS/ConvNext/14_10_24/L=6/symm_ramp_3x3/7/${SLURM_JOB_ID}.out &
Configuring sharding...
Number of distributed processes = 1
Number of total devices: 8
0/1 : global [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : local [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]
0/1 : hostname:  jean-zay-iam28
2024-10-17 08:01:06.130320: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.68. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
Double precision enabled =  True
chunk_size = 512
Running optimization...
Symmetry stage 0 on process 0:
Total number of model parameters = 188136
Using minSR
restoring checkpoint #0
Symmetry stage 1 on process 0:
Total number of model parameters = 188136
Using minSR
Symmetry stage 2 on process 0:
Total number of model parameters = 188136
Using minSR
Symmetry stage 3 on process 0:
Total number of model parameters = 188136
Using minSR
2024-10-17 14:44:50.591546: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_2_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.592215: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_4_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.592287: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
2024-10-17 14:44:50.592990: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.592393 1234518 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
E1017 14:44:50.593084 1234522 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
2024-10-17 14:44:50.593936: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_1_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.594678: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.594783 1234516 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
2024-10-17 14:44:50.595399: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_3_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.596131: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.596240 1234520 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
2024-10-17 14:44:50.597131: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_7_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.597805: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.597899 1234528 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
2024-10-17 14:44:50.598995: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_6_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.599768: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.599861 1234526 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
2024-10-17 14:44:50.600921: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_5_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.601737: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.601828 1234524 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
2024-10-17 14:44:50.602707: W external/xla/xla/tsl/framework/bfc_allocator.cc:497] Allocator (GPU_0_bfc) ran out of memory trying to allocate 68.81GiB (rounded to 73887504128)requested by op 
2024-10-17 14:44:50.603606: W external/xla/xla/tsl/framework/bfc_allocator.cc:508] *___________________________________________________________________________________________________
E1017 14:44:50.603717 1234514 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.
Traceback (most recent call last):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/run.py", line 158, in <module>
    sim_time, n_parameters = optimization(
                             ^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/deepnets/optimization/protocols.py", line 675, in symmetry_ramp_checkpoint
    gs.run_checkpointed(
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 214, in run_checkpointed
    for step in self.iter(n_iter, step_size, start=starting_iter):
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_checkpoint/_src/driver1/abstract_variational_driver.py", line 69, in iter
    dp = self._forward_and_backward()
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lustre/fswork/projects/rech/iqu/uvm91ap/repos/netket_pro/netket_pro/_src/driver/vmc_srt_ntk.py", line 394, in _forward_and_backward
    updates, self._cplx_split_updates, _ = SRt_ntk(
                                           ^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 73887503992 bytes.: while running replica 0 and partition 0 of a replicated computation (other replicas may have failed as well).
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
slurmstepd: error: *** STEP 156714.0 ON jean-zay-iam28 CANCELLED AT 2024-10-17T17:36:36 ***
slurmstepd: error: *** JOB 156714 ON jean-zay-iam28 CANCELLED AT 2024-10-17T17:36:36 ***
